{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaisakthism/Few-Shot-Semantic-Segmentation-Papers/blob/master/wbc_types.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2ghkkheZyGox"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4fvgMvQKpqU",
        "outputId": "b78d1a64-bfd4-41f4-b133-9de0df32cac5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATADIR = \"drive/MyDrive/LISC Database/LISC Database/Ground Truth Segmentation\"\n",
        "CATEGORIES = ['Baso/areaforexpert1','eosi/areaforexpert1','lymp/areaforexpert1','mixt/areaforexpert1','mono/areaforexpert1','neut/areaforexpert1']"
      ],
      "metadata": {
        "id": "VFx1XVfV5q5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VALIDDIR = \"drive/MyDrive/LISC Database/LISC Database/Main Dataset\"\n",
        "CATEGORIESV = ['Baso','eosi','lymp','mixt','mono','neut']"
      ],
      "metadata": {
        "id": "egwUFpFxw63M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = 225"
      ],
      "metadata": {
        "id": "QeTtvltAa7YE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = []\n",
        "\n",
        "def create_training_data(): \n",
        "  for category in CATEGORIES:\n",
        "    path = os.path.join(DATADIR, category)\n",
        "    class_num = CATEGORIES.index(category) #creating indexes for each of the type of WBCs\n",
        "    for img in os.listdir(path):\n",
        "      try: #if image is broken pass it\n",
        "        img_array = cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE) #reading the images in grayscale\n",
        "        new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
        "        training_data.append([new_array, class_num])\n",
        "      except Exception as e:\n",
        "        pass\n",
        "\n",
        "create_training_data()"
      ],
      "metadata": {
        "id": "GTVAqCOEGNMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_data = []\n",
        "\n",
        "def create_validation_data(): \n",
        "  for category in CATEGORIESV:\n",
        "    path = os.path.join(VALIDDIR, category)\n",
        "    class_num = CATEGORIESV.index(category) #creating indexes for each of the type of WBCs\n",
        "    for img in os.listdir(path):\n",
        "      try: #if image is broken pass it\n",
        "        img_array = cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE) #reading the images in grayscale\n",
        "        new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
        "        validation_data.append([new_array, class_num])\n",
        "      except Exception as e:\n",
        "        pass\n",
        "\n",
        "create_validation_data()"
      ],
      "metadata": {
        "id": "c_Bx-E07w3Ao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(training_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zC14MJPjG79E",
        "outputId": "840a512f-a185-448d-f749-2413bd912022"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#lets check for balanced data\n",
        "\n",
        "import random\n",
        "\n",
        "random.shuffle(training_data)"
      ],
      "metadata": {
        "id": "3qwwP_xXI6jJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sample in training_data[:10]:\n",
        "  print(sample[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0OObsfsJDfh",
        "outputId": "53f8f245-4824-45a3-c1c2-a3a4803a5b09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "2\n",
            "4\n",
            "4\n",
            "1\n",
            "1\n",
            "5\n",
            "5\n",
            "2\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = []\n",
        "y = []"
      ],
      "metadata": {
        "id": "GVDVMGBmJLFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for features,label in training_data:\n",
        "  X.append(features)\n",
        "  y.append(label)\n",
        "\n",
        "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)#1 because grayscale"
      ],
      "metadata": {
        "id": "E-RNj7T6JcCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#saving our data so we dont have to do it everytime\n",
        "\n",
        "import pickle\n",
        "\n",
        "pickle_out = open(\"X.pickle\", \"wb\")\n",
        "pickle.dump(X, pickle_out)\n",
        "pickle_out.close()\n",
        "\n",
        "pickle_out = open(\"y.pickle\", \"wb\")\n",
        "pickle.dump(y, pickle_out)\n",
        "pickle_out.close()"
      ],
      "metadata": {
        "id": "ekWO2jDnJ-YW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pickle_in = open(\"X.pickle\", \"rb\")\n",
        "X = pickle.load(pickle_in)"
      ],
      "metadata": {
        "id": "uS4ZPm4uLNtm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
        "import pickle"
      ],
      "metadata": {
        "id": "FgjGKoBELzop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = pickle.load(open(\"X.pickle\",\"rb\"))\n",
        "y = pickle.load(open(\"y.pickle\",\"rb\"))"
      ],
      "metadata": {
        "id": "vz8LETonVibL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llp9FxUZVs1F",
        "outputId": "8c52525b-827c-4678-e7db-b18436916fcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "250"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = X/255.0"
      ],
      "metadata": {
        "id": "8surV5MtQzCx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = np.array(y)"
      ],
      "metadata": {
        "id": "dk5SGPANWM6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "#First Layer of the CNN\n",
        "model.add(Conv2D(64, (3,3), input_shape = X.shape[1:]))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size = (2,2)))"
      ],
      "metadata": {
        "id": "558JsSvDREUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Second Layer\n",
        "model.add(Conv2D(64, (3,3)))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size = (2,2)))"
      ],
      "metadata": {
        "id": "TdWAX2zpSuoL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Final Layer\n",
        "model.add(Flatten())#required as Dense requires 1D data\n",
        "model.add(Dense(64))"
      ],
      "metadata": {
        "id": "9mqFgfVETCLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Output Layer\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))"
      ],
      "metadata": {
        "id": "8_PLi0sNTYpn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss = \"categorical_crossentropy\",\n",
        "              optimizer = \"adam\",\n",
        "              metrics = ['accuracy']\n",
        "              )"
      ],
      "metadata": {
        "id": "4SNvNdCnT3CC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X, y, batch_size = 10, validation_split = 0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8NcSO96UMWW",
        "outputId": "bfeda028-af18-40bf-a76a-ef34797ccc8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 [==============================] - 30s 1s/step - loss: 0.0000e+00 - accuracy: 0.1600 - val_loss: 0.0000e+00 - val_accuracy: 0.0800\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4fd809e150>"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**VGG16**"
      ],
      "metadata": {
        "id": "Ytf8PQS5pnv3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Input, Lambda, Dense, Flatten\n",
        "from keras.models import Model\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "wXQmzO5TC8xD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = [224, 224]"
      ],
      "metadata": {
        "id": "vo2BL1uHC-Jd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
        "vgg.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjs5F3i0DB7n",
        "outputId": "7b188757-3071-4d7a-d886-d78ee2f7e814"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in vgg.layers:\n",
        "  layer.trainable = False"
      ],
      "metadata": {
        "id": "xZG0V9gKDEW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = Flatten()(vgg.output)\n",
        "x = Dense(1, activation='softmax')(x)\n",
        "model = Model(inputs=vgg.input, outputs=x)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKd3406pDGUJ",
        "outputId": "925c25c5-c1a2-428e-f5cd-a9223c0b5dce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten_11 (Flatten)        (None, 25088)             0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 1)                 25089     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,739,777\n",
            "Trainable params: 25,089\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "  loss='categorical_crossentropy',\n",
        "  optimizer='adam',\n",
        "  metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "J85WEZS2DIty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = '/content/drive/MyDrive/DATA/train_data'\n",
        "valid_path = '/content/drive/MyDrive/DATA/test_data'\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "training_set = train_datagen.flow_from_directory(train_path,\n",
        "                                                 target_size = (224, 224),\n",
        "                                                 batch_size = 16,\n",
        "                                                 )\n",
        "test_set = test_datagen.flow_from_directory(valid_path,\n",
        "                                            target_size = (224, 224),\n",
        "                                            batch_size = 16,\n",
        "                                            )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNF2NL3LDK-O",
        "outputId": "c499a7f4-1d85-4fcd-c2c1-656fbde23fbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 250 images belonging to 6 classes.\n",
            "Found 250 images belonging to 6 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r = model.fit_generator(\n",
        "  training_set,  \n",
        "  validation_data=test_set,\n",
        "  epochs=15,\n",
        "  steps_per_epoch=len(training_set),\n",
        "  validation_steps=len(test_set)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "jqLmPO9yJ531",
        "outputId": "8a392f24-477b-4a04-f628-1ff587ea2bc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: `model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-159-4aa922e51c97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1244\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1245\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1246\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1248\u001b[0m   def evaluate_generator(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    793\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training_generator_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training_generator_v1.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1048\u001b[0m     x, y, sample_weights = self._standardize_user_data(\n\u001b[1;32m   1049\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         extract_tensors_from_dataset=True)\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;31m# If `self._distribution_strategy` is True, then we are in a replica context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2327\u001b[0m         \u001b[0mis_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2328\u001b[0m         \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2329\u001b[0;31m         batch_size=batch_size)\n\u001b[0m\u001b[1;32m   2330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2331\u001b[0m   def _standardize_tensors(self, x, y, sample_weight, run_eagerly, dict_inputs,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py\u001b[0m in \u001b[0;36m_standardize_tensors\u001b[0;34m(self, x, y, sample_weight, run_eagerly, dict_inputs, is_dataset, class_weight, batch_size)\u001b[0m\n\u001b[1;32m   2433\u001b[0m           \u001b[0;31m# Additional checks to avoid users mistakenly using improper loss fns.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2434\u001b[0m           training_utils_v1.check_loss_and_target_compatibility(\n\u001b[0;32m-> 2435\u001b[0;31m               y, self._feed_loss_fns, feed_output_shapes)\n\u001b[0m\u001b[1;32m   2436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2437\u001b[0m       sample_weights, _, _ = training_utils.handle_partial_sample_weights(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training_utils_v1.py\u001b[0m in \u001b[0;36mcheck_loss_and_target_compatibility\u001b[0;34m(targets, loss_fns, output_shapes)\u001b[0m\n\u001b[1;32m    811\u001b[0m           raise ValueError('A target array with shape ' + str(y.shape) +\n\u001b[1;32m    812\u001b[0m                            \u001b[0;34m' was passed for an output of shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 813\u001b[0;31m                            \u001b[0;34m' while using as loss `'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    814\u001b[0m                            \u001b[0;34m'This loss expects targets to have the same shape '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m                            'as the output.')\n",
            "\u001b[0;31mValueError\u001b[0m: A target array with shape (10, 6) was passed for an output of shape (None, 1) while using as loss `categorical_crossentropy`. This loss expects targets to have the same shape as the output."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**InceptionV3**"
      ],
      "metadata": {
        "id": "UkWg6oAsLw8n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model"
      ],
      "metadata": {
        "id": "-rC2yPFsL0Ao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.inception_v3 import InceptionV3"
      ],
      "metadata": {
        "id": "7fF3DRrwM1Vu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), # Shape of our images\n",
        "                                include_top = False, # Leave out the last fully connected layer\n",
        "                                weights = 'imagenet')"
      ],
      "metadata": {
        "id": "ll493OJpM8od"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False"
      ],
      "metadata": {
        "id": "4Q7W7Z2VNM6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')>0.1):\n",
        "      print(\"\\nReached 10% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True"
      ],
      "metadata": {
        "id": "OvT-cNBvNUNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(pre_trained_model.output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense  (6, activation='sigmoid')(x)           \n",
        "\n",
        "model = Model( pre_trained_model.input, x) \n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss = 'sparse_categorical_crossentropy', \n",
        "              metrics = ['acc'])"
      ],
      "metadata": {
        "id": "Sos70a24NYoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = '/content/drive/MyDrive/DATA/train_data'\n",
        "validation_dir = '/content/drive/MyDrive/DATA/test_data'\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
        "                                   rotation_range = 40,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    batch_size = 20,\n",
        "                                                    class_mode = 'binary', \n",
        "                                                    target_size = (150, 150))     \n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory( validation_dir,\n",
        "                                                          batch_size  = 20,\n",
        "                                                          class_mode  = 'binary', \n",
        "                                                          target_size = (150, 150))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4HnnYPxNgDP",
        "outputId": "19e3defc-e0da-49c2-8e46-e9c1313ac18a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 250 images belonging to 6 classes.\n",
            "Found 250 images belonging to 6 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = myCallback()\n",
        "history = model.fit_generator(\n",
        "            train_generator,\n",
        "            validation_data = validation_generator,\n",
        "            steps_per_epoch = 100,\n",
        "            epochs = 15,\n",
        "            validation_steps = 50,\n",
        "            verbose = 2,\n",
        "            callbacks=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WN0RUv_zNzMv",
        "outputId": "fc1049f6-4f39-4377-ea1d-22f29191e09b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: UserWarning: `model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2045: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates = self.state_updates\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100/100 - 277s - loss: 1.2409 - acc: 0.6208 - val_loss: 2.5963 - val_acc: 0.1505 - 277s/epoch - 3s/step\n",
            "Epoch 2/15\n",
            "100/100 - 177s - loss: 1.1221 - acc: 0.6383 - val_loss: 3.0213 - val_acc: 0.2268 - 177s/epoch - 2s/step\n",
            "Epoch 3/15\n",
            "100/100 - 176s - loss: 0.9985 - acc: 0.6833 - val_loss: 3.5123 - val_acc: 0.1464 - 176s/epoch - 2s/step\n",
            "Epoch 4/15\n",
            "100/100 - 180s - loss: 1.0480 - acc: 0.6521 - val_loss: 4.1872 - val_acc: 0.1629 - 180s/epoch - 2s/step\n",
            "Epoch 5/15\n",
            "100/100 - 177s - loss: 0.9079 - acc: 0.7094 - val_loss: 5.1736 - val_acc: 0.1825 - 177s/epoch - 2s/step\n",
            "Epoch 6/15\n",
            "100/100 - 177s - loss: 0.9226 - acc: 0.7135 - val_loss: 3.5406 - val_acc: 0.1969 - 177s/epoch - 2s/step\n",
            "Epoch 7/15\n",
            "100/100 - 173s - loss: 0.8872 - acc: 0.7219 - val_loss: 5.2683 - val_acc: 0.1515 - 173s/epoch - 2s/step\n",
            "Epoch 8/15\n",
            "100/100 - 176s - loss: 0.8875 - acc: 0.7125 - val_loss: 5.3150 - val_acc: 0.1670 - 176s/epoch - 2s/step\n",
            "Epoch 9/15\n",
            "100/100 - 177s - loss: 0.8418 - acc: 0.7259 - val_loss: 5.0700 - val_acc: 0.1794 - 177s/epoch - 2s/step\n",
            "Epoch 10/15\n",
            "100/100 - 177s - loss: 0.8135 - acc: 0.7417 - val_loss: 5.2583 - val_acc: 0.1608 - 177s/epoch - 2s/step\n",
            "Epoch 11/15\n",
            "100/100 - 184s - loss: 0.7936 - acc: 0.7542 - val_loss: 4.7853 - val_acc: 0.2072 - 184s/epoch - 2s/step\n",
            "Epoch 12/15\n",
            "100/100 - 178s - loss: 0.7698 - acc: 0.7451 - val_loss: 4.3310 - val_acc: 0.2082 - 178s/epoch - 2s/step\n",
            "Epoch 13/15\n",
            "100/100 - 179s - loss: 0.7738 - acc: 0.7615 - val_loss: 5.5217 - val_acc: 0.2093 - 179s/epoch - 2s/step\n",
            "Epoch 14/15\n",
            "100/100 - 177s - loss: 0.7821 - acc: 0.7505 - val_loss: 6.4969 - val_acc: 0.1320 - 177s/epoch - 2s/step\n",
            "Epoch 15/15\n",
            "100/100 - 178s - loss: 0.7663 - acc: 0.7585 - val_loss: 6.7759 - val_acc: 0.1825 - 178s/epoch - 2s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "QntJrkI7cUCi",
        "outputId": "71b401e7-de50-4356-c7b7-48b8a1b45d1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}